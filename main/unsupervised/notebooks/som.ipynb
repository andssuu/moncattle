{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "som.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dnm01WsNosXo",
        "outputId": "d08bb7d8-4ebb-47c2-a45b-56d6734ef313"
      },
      "source": [
        "!git clone https://github.com/andssuu/moncattle.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'moncattle'...\n",
            "remote: Enumerating objects: 24, done.\u001b[K\n",
            "remote: Counting objects: 100% (24/24), done.\u001b[K\n",
            "remote: Compressing objects: 100% (21/21), done.\u001b[K\n",
            "remote: Total 24 (delta 4), reused 12 (delta 1), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (24/24), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62X-QCfTnyvn"
      },
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib import patches as patches\n",
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "\n",
        "def load_data(url, normalize_data, normalize_by_column):\n",
        "    df = pd.read_csv(url)\n",
        "    # remove a ultima coluna (dados)\n",
        "    #data = df[df.columns[:-1]]\n",
        "    #data = df[df.columns[:4]]\n",
        "    # retorna a última coluna (rótulos)\n",
        "    #labels = df[df.columns[-1]]\n",
        "\n",
        "    data = df[df.idColar == \"A2\"].iloc[:, 1:4]\n",
        "    labels = df[df.idColar == \"A2\"].iloc[:, -1]\n",
        "\n",
        "    # check if data needs to be normalised\n",
        "    if normalize_data:\n",
        "        if normalize_by_column:\n",
        "            # normalise along each column\n",
        "            col_maxes = data.max(axis=0)\n",
        "            normalized_data = (data - col_maxes.min()) / \\\n",
        "                (col_maxes.max() - col_maxes.min())\n",
        "        else:\n",
        "            # normalise entire dataset\n",
        "            normalized_data = (data - data.min()) / (data.max() - data.min())\n",
        "    return normalized_data, labels\n",
        "\n",
        "def find_bmu(t, net, m):\n",
        "    \"\"\"\n",
        "        Encontra o neurônio vencedor pra um dado vetor de entrada, t, na rede SOM\n",
        "        Retorna: (bmu, bmu_idx) onde bmu é o neurônio vencedor BMU\n",
        "                 e bmu_idx é a coordenada do vetor na rede SOM\n",
        "    \"\"\"\n",
        "    bmu_idx = np.array([0, 0])\n",
        "    # set the initial minimum distance to a huge number\n",
        "    # define um número grande pra distância mínima inicial\n",
        "    min_dist = np.iinfo(np.int).max\n",
        "    # calcula a distância entre cada neurônio e a entrada\n",
        "    for x in range(net.shape[0]):\n",
        "        for y in range(net.shape[1]):\n",
        "            w = net[x, y, :].reshape(m, 1)\n",
        "            sq_dist = np.sum((w - t) ** 2)\n",
        "            if sq_dist < min_dist:\n",
        "                min_dist = sq_dist\n",
        "                bmu_idx = np.array([x, y])\n",
        "    # obtém o vetor correspondente a bmu_idx\n",
        "    bmu = net[bmu_idx[0], bmu_idx[1], :].reshape(m, 1)\n",
        "    # retorna (bmu, bmu_idx)\n",
        "    return (bmu, bmu_idx)\n",
        "\n",
        "def decay_radius(initial_radius, i, time_constant):\n",
        "    return initial_radius * np.exp(-i / time_constant)\n",
        "\n",
        "def decay_learning_rate(initial_learning_rate, i, n_iterations):\n",
        "    return initial_learning_rate * np.exp(-i / n_iterations)\n",
        "\n",
        "def compute_neighborhood(distance, radius):\n",
        "    return np.exp(-distance / (2 * (radius**2)))\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    # Tamanho do mapa\n",
        "    X = 10\n",
        "    Y = 10\n",
        "    network_dimensions = np.array([X, Y])\n",
        "    n_iterations = 10000\n",
        "    # taxa de aprendizado\n",
        "    init_learning_rate = 0.1\n",
        "    # Normalização dos dados\n",
        "    normalize_data = True\n",
        "    # se True, normaliza em relação a toda a base de dados\n",
        "    # se False, normaliza entre [0 1] levando em conta cada coluna\n",
        "    normalize_by_column = False\n",
        "    # cria raio inicial de acordo com o tamanho inicial do mapa da SOM\n",
        "    init_radius = max(network_dimensions[0], network_dimensions[1]) / 2\n",
        "    # constante de tempo que decai com o tempo\n",
        "    time_constant = n_iterations / np.log(init_radius)\n",
        "    # carrega a base de dados\n",
        "    local = 'moncattle/data/embrapa.csv'\n",
        "    data, labels = load_data(local, normalize_data, normalize_by_column)\n",
        "    # pega tamanho da base de dados\n",
        "    m = data.shape[1]\n",
        "    n = data.shape[0]\n",
        "    # transforma rótulos do conjunto de treinamento em numeros pra mostrar no mapa\n",
        "    le = preprocessing.LabelEncoder()\n",
        "    le.fit(labels.values)\n",
        "    training_labels_transformed = le.transform(labels.values)\n",
        "    c = le.classes_\n",
        "    label_map = np.zeros((X, Y, len(c)))\n",
        "    # inicialização dos pesos m=dimensional pra cada neurônio da matriz SOM\n",
        "    net = np.random.random((network_dimensions[0], network_dimensions[1], m))\n",
        "    for i in range(n_iterations):\n",
        "        #print('Iteration %d' % i)\n",
        "        # seleciona um exemplo aleatoriamente da base de dados\n",
        "        random_example = np.random.randint(0, n)\n",
        "        t = data.iloc[random_example].values.reshape(np.array([m, 1]))\n",
        "        # calcula neurônio mais próximo a este exemplo (BMU)\n",
        "        bmu, bmu_idx = find_bmu(t, net, m)\n",
        "        # seleciona a classe do exemplo (Apenas pra vias de informação no mapa)\n",
        "        class_index = list(c).index(labels[random_example])\n",
        "        lab = label_map[bmu_idx[0], bmu_idx[1]]\n",
        "        lab[class_index] = lab[class_index]+1\n",
        "        # associa o neurônio a esta classe\n",
        "        label_map[bmu_idx[0], bmu_idx[1]] = lab\n",
        "        # Decresce os parâmetros da SOM\n",
        "        r = decay_radius(init_radius, i, time_constant)\n",
        "        l = decay_learning_rate(init_learning_rate, i, n_iterations)\n",
        "        # Atualiza o vetor de Pesos da rede SOM para todos os neurônios da rede\n",
        "        for x in range(net.shape[0]):\n",
        "            for y in range(net.shape[1]):\n",
        "                w = net[x, y, :].reshape(m, 1)\n",
        "                # calcula a distância do neurônio ao neurônio vencedor\n",
        "                w_dist = np.sum((np.array([x, y]) - bmu_idx) ** 2)\n",
        "                # se distância está dentro do raio estipulado r^2\n",
        "                if w_dist <= r**2:\n",
        "                    # calcula a função de vizinhança\n",
        "                    influence = compute_neighborhood(w_dist, r)\n",
        "                    # atualiza os pesos\n",
        "                    # w(t+1) = w(t) + (learning rate * h * distancia)\n",
        "                    new_w = w + (l * influence * (t - w))\n",
        "                    # coloca o novo peso na rede na posição X,Y\n",
        "                    net[x, y, :] = new_w.reshape(1, m)\n",
        "\n",
        "    fig = plt.figure()\n",
        "    # setup axes\n",
        "    ax = fig.add_subplot(111, aspect='equal')\n",
        "    ax.set_xlim((0, net.shape[0]+1))\n",
        "    ax.set_ylim((0, net.shape[1]+1))\n",
        "    ax.set_title('Self-Organising Map after %d iterations' % n_iterations)\n",
        "\n",
        "    # plot the rectangles\n",
        "    for x in range(1, net.shape[0] + 1):\n",
        "        for y in range(1, net.shape[1] + 1):\n",
        "            # print(net[x-1,y-1,:])\n",
        "            m = label_map[x-1, y-1]\n",
        "            name_class = c[np.argmax(m)]\n",
        "            ax.add_patch(patches.Rectangle((x-0.5, y-0.5), 1, 1,\n",
        "                                        facecolor=net[x-1, y-1, :],\n",
        "                                        edgecolor='none', label='sdsad'))\n",
        "            ax.text(x, y, name_class,\n",
        "                    horizontalalignment='center', verticalalignment='center',\n",
        "                    fontsize=7, color='red')\n",
        "    plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}